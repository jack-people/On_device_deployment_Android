package com.agenew.clip

import android.content.Context
import android.graphics.Bitmap
import android.util.Log
import org.tensorflow.lite.DataType
import org.tensorflow.lite.Interpreter
import org.tensorflow.lite.gpu.CompatibilityList
import org.tensorflow.lite.gpu.GpuDelegate
import org.tensorflow.lite.support.common.FileUtil
import org.tensorflow.lite.support.common.ops.NormalizeOp
import org.tensorflow.lite.support.image.ImageProcessor
import org.tensorflow.lite.support.image.TensorImage
import org.tensorflow.lite.support.image.ops.ResizeOp
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.sqrt

class ClipPredictor(private val context: Context) {

    private var imageInterpreter: Interpreter? = null
    private var textInterpreter: Interpreter? = null

    // CLIP æ ‡å‡†å‚æ•°
    private val inputImageSize = 224
    private val textContextLength = 77
    private val embeddingSize = 512 // æ ¹æ®ä½ çš„æ¨¡å‹ï¼Œå¯èƒ½æ˜¯ 512, 768 ç­‰

    // CLIP çš„å½’ä¸€åŒ–å‚æ•° (OpenAI åŸç‰ˆå‚æ•°)
//    private val mean = floatArrayOf(0.48145466f, 0.4578275f, 0.40821073f)
//    private val std = floatArrayOf(0.26862954f, 0.26130258f, 0.27577711f)

    private val mean = floatArrayOf(122.77f, 116.75f, 104.09f)
    private val std = floatArrayOf(68.50f, 66.63f, 70.32f)

    init {
        initModels()
    }

    private fun initModels() {
        // 1. å‡†å¤‡å›¾åƒæ¨¡å‹çš„ Options (å°è¯• GPU)
        val imageOptions = Interpreter.Options().apply {
            val compatList = CompatibilityList()
            if (compatList.isDelegateSupportedOnThisDevice) {
                val delegateOptions = compatList.bestOptionsForThisDevice
                addDelegate(GpuDelegate(delegateOptions))
            } else {
                setNumThreads(4)
            }
            setUseXNNPACK(true) // å³ä½¿æ˜¯ CPU æ¨¡å¼ä¹ŸåŠ é€Ÿ
        }

        // 2. å‡†å¤‡æ–‡æœ¬æ¨¡å‹çš„ Options (å»ºè®®ä¼˜å…ˆ CPUï¼Œå› ä¸º CLIP Text å…¼å®¹æ€§å·®)
        val textOptions = Interpreter.Options().apply {
            setNumThreads(4)
            setUseXNNPACK(true)
        }

        try {
            // åŠ è½½å›¾åƒæ¨¡å‹
            imageInterpreter = Interpreter(
                FileUtil.loadMappedFile(context, "clip_image_encoder_float32_new.tflite"),
                imageOptions
            )
            Log.d("TFLite", "å›¾åƒæ¨¡å‹åŠ è½½æˆåŠŸ")
        } catch (e: Exception) {
            Log.e("TFLite", "å›¾åƒæ¨¡å‹ GPU åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯• CPU é™çº§: ${e.message}")
            val fallbackOptions = Interpreter.Options().setNumThreads(4)
            imageInterpreter = Interpreter(
                FileUtil.loadMappedFile(context, "clip_image_encoder_float32_new.tflite"),
                fallbackOptions
            )
        }

        try {
            // åŠ è½½æ–‡æœ¬æ¨¡å‹ (ç›´æ¥ç”¨ textOptionsï¼Œé¿å…ä¹‹å‰æŠ¥é”™çš„ GPU é—®é¢˜)
            textInterpreter = Interpreter(
                FileUtil.loadMappedFile(context, "clip_text_encoder_float32_new.tflite"),
                textOptions
            )
            Log.d("TFLite", "æ–‡æœ¬æ¨¡å‹åŠ è½½æˆåŠŸ")
        } catch (e: Exception) {
            Log.e("TFLite", "æ–‡æœ¬æ¨¡å‹åŠ è½½å¤±è´¥: ${e.message}")
        }

        // --- ğŸ•µï¸â€â™€ï¸ ä¾¦æ¢ä»£ç å¼€å§‹ ---
        val outputCount = imageInterpreter?.outputTensorCount ?: 0
        Log.e("ZJJ_DEBUG", "--------------------------------------------------")
        Log.e("ZJJ_DEBUG", "æ¨¡å‹å…±æœ‰ $outputCount ä¸ªè¾“å‡ºç«¯")

        for (i in 0 until outputCount) {
            val tensor = imageInterpreter?.getOutputTensor(i)
            val shape = tensor?.shape()?.contentToString()
            val bytes = tensor?.numBytes()

            Log.e("ZJJ_DEBUG", "Output Index [$i]: Shape=$shape, Bytes=$bytes")

            if (bytes == 2048) { // 512 * 4
                Log.e("ZJJ_DEBUG", "âœ… æ‰¾åˆ°ç›®æ ‡ï¼çœŸæ­£çš„ Embedding åœ¨ Index [$i]")
            } else if (bytes == 153600) {
                Log.e("ZJJ_DEBUG", "âŒ å‘ç°åŸå§‹å±‚ï¼è¿™æ˜¯å¯¼è‡´æŠ¥é”™çš„å…ƒå‡¶ (Index [$i])")
            }
        }
        Log.e("ZJJ_DEBUG", "--------------------------------------------------")
        // --- ä¾¦æ¢ä»£ç ç»“æŸ ---

        // --- ğŸ•µï¸â€â™€ï¸ ä¾¦æ¢ä»£ç å¼€å§‹ ---
        val outputCountText = textInterpreter?.outputTensorCount ?: 0
        Log.e("ZJJ_DEBUG", "--------------------------------------------------")
        Log.e("ZJJ_DEBUG", "æ¨¡å‹å…±æœ‰ $outputCountText ä¸ªè¾“å‡ºç«¯")

        for (i in 0 until outputCount) {
            val tensor = textInterpreter?.getOutputTensor(i)
            val shape = tensor?.shape()?.contentToString()
            val bytes = tensor?.numBytes()

            Log.e("ZJJ_DEBUG", "Output Index [$i]: Shape=$shape, Bytes=$bytes")

            if (bytes == 2048) { // 512 * 4
                Log.e("ZJJ_DEBUG", "âœ… æ‰¾åˆ°ç›®æ ‡ï¼çœŸæ­£çš„ Embedding åœ¨ Index [$i]")
            } else if (bytes == 157696) {
                Log.e("ZJJ_DEBUG", "âŒ å‘ç°åŸå§‹å±‚ï¼è¿™æ˜¯å¯¼è‡´æŠ¥é”™çš„å…ƒå‡¶ (Index [$i])")
            }
        }
        Log.e("ZJJ_DEBUG", "--------------------------------------------------")
        // --- ä¾¦æ¢ä»£ç ç»“æŸ ---

    }

    /**
     * 1. å›¾åƒç¼–ç  (ä¿®å¤ç‰ˆï¼šæŒ‡å®šè¯»å– Index 1)
     */
    fun encodeImage(bitmap: Bitmap): FloatArray {
        // 1. é¢„å¤„ç†å›¾ç‰‡ (ä¿æŒä¸å˜)
        val imageProcessor = ImageProcessor.Builder()
            .add(ResizeOp(inputImageSize, inputImageSize,
                ResizeOp.ResizeMethod.BILINEAR))
            .add(NormalizeOp(mean, std))
            .build()

        var tensorImage = TensorImage(DataType.FLOAT32)
        tensorImage.load(bitmap)
        tensorImage = imageProcessor.process(tensorImage)

        // 2. å‡†å¤‡è¾“å…¥ (å¿…é¡»åŒ…è£…æˆæ•°ç»„ï¼Œå› ä¸ºæˆ‘ä»¬è¦ç”¨ runForMultipleInputsOutputs)
        val inputs = arrayOf(tensorImage.buffer)

        // 3. å‡†å¤‡è¾“å‡º Map
        // å…³é”®ç‚¹ï¼šæˆ‘ä»¬è¦æŠŠ Buffer ç»‘å®šåˆ° Index 1ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„ Index 0
        val outputs = HashMap<Int, Any>()

        val outputBuffer = ByteBuffer.allocateDirect(embeddingSize * 4) // 512 * 4 = 2048
        outputBuffer.order(ByteOrder.nativeOrder())

        // ğŸ”¥ã€æ ¸å¿ƒä¿®æ”¹ã€‘è¿™é‡Œå¡« 1ï¼Œå¯¹åº” Log ä¸­çš„ "âœ… æ‰¾åˆ°ç›®æ ‡ Index [1]"
        outputs[1] = outputBuffer

        // 4. è¿è¡Œæ¨ç† (ä½¿ç”¨å¤šè¾“å…¥è¾“å‡º API)
        imageInterpreter?.runForMultipleInputsOutputs(inputs, outputs)

        // 5. è·å–ç»“æœå¹¶å½’ä¸€åŒ–
        outputBuffer.rewind()
        val embedding = FloatArray(embeddingSize)
        outputBuffer.asFloatBuffer().get(embedding)
        return normalizeVector(embedding)
    }

    /**
     * 2. æ–‡æœ¬ç¼–ç 
     * @param tokenIds: å¿…é¡»æ˜¯ Tokenizer å¤„ç†åçš„ ID æ•°ç»„ (ä¾‹å¦‚ int[77])
     */
//    fun encodeText(tokenIds: IntArray): FloatArray {
//        // ç¡®ä¿è¾“å…¥ Shape ç¬¦åˆæ¨¡å‹è¦æ±‚ï¼Œé€šå¸¸æ˜¯ [1, 77]
//        // è¿™é‡Œéœ€è¦å°† IntArray è½¬æ¢ä¸º ByteBuffer æˆ–è€…ç›´æ¥ä¼ å…¥å¤šç»´æ•°ç»„
//        val input = Array(1) { tokenIds }
//        val outputBuffer = ByteBuffer.allocateDirect(embeddingSize * 4)
//        outputBuffer.order(ByteOrder.nativeOrder())
//
//        textInterpreter?.run(input, outputBuffer)
//
//        outputBuffer.rewind()
//        val embedding = FloatArray(embeddingSize)
//        outputBuffer.asFloatBuffer().get(embedding)
//        return normalizeVector(embedding)
//    }

    /**
     * æ–‡æœ¬ç¼–ç  (é€‚é… PyTorch å¯¼å‡ºçš„åŒè¾“å…¥æ¨¡å‹)
     */
//    fun encodeText(tokenIds: IntArray): FloatArray {
//        // 1. å‡†å¤‡ Input IDs
//        // PyTorch æ¨¡å‹é€šå¸¸éœ€è¦ Long (Int64) æˆ– Int32ï¼Œè§†å¯¼å‡ºæ—¶çš„é…ç½®è€Œå®š
//        // å¦‚æœæŠ¥é”™ç±»å‹ä¸åŒ¹é…ï¼ŒæŠŠ IntBuffer æ¢æˆ LongBuffer
//        val inputIdsBuffer = ByteBuffer.allocateDirect(1 * 77 * 4) // å‡è®¾æ˜¯ Int32
//        inputIdsBuffer.order(ByteOrder.nativeOrder())
//        inputIdsBuffer.asIntBuffer().put(tokenIds)
//
//        // 2. å‡†å¤‡ Attention Mask
//        // å¯¹äºæ¨ç†ï¼ŒMask é€šå¸¸å…¨æ˜¯ 1 (å…³æ³¨æ‰€æœ‰ Token)
//        // é™¤éä½ æœ‰ Padding (è¡¥0) çš„éƒ¨åˆ†ï¼Œè¡¥0çš„åœ°æ–¹ Mask åº”è¯¥æ˜¯ 0
//        val maskArray = IntArray(77) { index ->
//            if (tokenIds[index] != 0) 1 else 0 // ç®€å•é€»è¾‘ï¼šé0å³æœ‰æ•ˆ
//        }
//        val maskBuffer = ByteBuffer.allocateDirect(1 * 77 * 4)
//        maskBuffer.order(ByteOrder.nativeOrder())
//        maskBuffer.asIntBuffer().put(maskArray)
//
//        // 3. æ„å»ºè¾“å…¥æ•°ç»„ (é¡ºåºå¿…é¡»å’Œ ONNX å¯¼å‡ºçš„ input_names é¡ºåºä¸€è‡´)
//        // é€šå¸¸æ˜¯ [input_ids, attention_mask]
//        val inputs = arrayOf(inputIdsBuffer, maskBuffer)
//
//        // 4. å‡†å¤‡è¾“å‡º Map
//        val outputMap = HashMap<Int, Any>()
//        val outputBuffer = ByteBuffer.allocateDirect(512 * 4) // Float output
//        outputBuffer.order(ByteOrder.nativeOrder())
//        outputMap[0] = outputBuffer
//
//        // 5. è¿è¡Œæ¨ç† (ä½¿ç”¨ runForMultipleInputsOutputs)
//        textInterpreter?.runForMultipleInputsOutputs(inputs, outputMap)
//
//        // 6. è·å–ç»“æœ
//        outputBuffer.rewind()
//        val embedding = FloatArray(512)
//        outputBuffer.asFloatBuffer().get(embedding)
//        return normalizeVector(embedding)
//    }


    /**
     * æ–‡æœ¬ç¼–ç  (æœ€ç»ˆä¿®å¤ç‰ˆï¼šInt64è¾“å…¥ + æŒ‡å®šè¾“å‡ºIndex 1)
     */
    fun encodeText(tokenIds: IntArray): FloatArray {
        // --- 1. å‡†å¤‡ Input IDs (Int64/Long) ---
        // ä¹‹å‰æŠ¥é”™ input_ids mismatchï¼Œå¿…é¡»ç”¨ 8 å­—èŠ‚çš„ Long
        val inputIdsBuffer = ByteBuffer.allocateDirect(1 * 77 * 8)
        inputIdsBuffer.order(ByteOrder.nativeOrder())
        for (id in tokenIds) {
            inputIdsBuffer.putLong(id.toLong())
        }

        // --- 2. å‡†å¤‡ Attention Mask (Int64/Long) ---
        val maskBuffer = ByteBuffer.allocateDirect(1 * 77 * 8)
        maskBuffer.order(ByteOrder.nativeOrder())
        for (id in tokenIds) {
            val maskVal = if (id != 0) 1L else 0L
            maskBuffer.putLong(maskVal)
        }

        // é‡ç½® Buffer æŒ‡é’ˆ
        inputIdsBuffer.rewind()
        maskBuffer.rewind()

        // æ„é€ è¾“å…¥æ•°ç»„ [input_ids, attention_mask]
        val inputs = arrayOf(inputIdsBuffer, maskBuffer)

        // --- 3. å‡†å¤‡è¾“å‡º (ä¿®å¤ç‚¹åœ¨è¿™é‡Œï¼ï¼ï¼) ---
        val outputs = HashMap<Int, Any>()
        val outputBuffer = ByteBuffer.allocateDirect(embeddingSize * 4) // 512 * 4 = 2048
        outputBuffer.order(ByteOrder.nativeOrder())

        // âŒ ä¹‹å‰æ˜¯ outputs[0] = outputBuffer
        // âœ… æ ¹æ® Logï¼Œæ­£ç¡®çš„ Embedding åœ¨ Index 1
        outputs[1] = outputBuffer

        // --- 4. è¿è¡Œæ¨ç† ---
        textInterpreter?.runForMultipleInputsOutputs(inputs, outputs)

        // --- 5. è·å–ç»“æœ ---
        outputBuffer.rewind()
        val embedding = FloatArray(embeddingSize)
        outputBuffer.asFloatBuffer().get(embedding)

        return normalizeVector(embedding)
    }

    /**
     * è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
     */
    fun calculateSimilarity(imageEmb: FloatArray, textEmb: FloatArray): Float {
        var dotProduct = 0.0f
        for (i in imageEmb.indices) {
            dotProduct += imageEmb[i] * textEmb[i]
        }
        // å› ä¸ºæˆ‘ä»¬ä¹‹å‰å·²ç»åšäº† L2 å½’ä¸€åŒ–ï¼Œæ‰€ä»¥ç‚¹ç§¯å°±æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦
        return dotProduct
    }

    // L2 å½’ä¸€åŒ–å‘é‡
    private fun normalizeVector(v: FloatArray): FloatArray {
        var sum = 0.0f
        for (x in v) sum += x * x
        val magnitude = sqrt(sum)
        if (magnitude > 0) {
            for (i in v.indices) v[i] /= magnitude
        }
        return v
    }

    fun close() {
        imageInterpreter?.close()
        textInterpreter?.close()
    }
}